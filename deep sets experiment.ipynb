{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from dataGenerator import make_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_conv(mag_input):\n",
    "    \"\"\"extracts features from the magnetic field information\n",
    "    \"\"\"\n",
    "    mag_features = mag_input\n",
    "    return mag_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_net(mag_features, st_loc):\n",
    "    \"\"\"aggregates information from magnetic field data and positions\n",
    "    \"\"\"\n",
    "    st_features = mag_features\n",
    "    return st_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_conv(global_params):\n",
    "    \"\"\"extracts features from the global parameters (solar wind, etc.)\n",
    "    \"\"\"\n",
    "    global_features = None\n",
    "    return global_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(st_features, global_features):\n",
    "    \"\"\"adds up the station vectors, concatenates with the global features,\n",
    "    outputs the substorm prediction\n",
    "    \"\"\"\n",
    "    model_output = st_features\n",
    "    return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(model_output, ss_occurred, ss_time, ss_loc):\n",
    "    \"\"\"calculates loss based on model output and the substorm occurance\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b603b3ca9d22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss_occurred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mtrain_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mSTEPS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    497\u001b[0m                        \u001b[1;34m\"Optimizer.GATE_OP, Optimizer.GATE_GRAPH.  Not %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                        gate_gradients)\n\u001b[1;32m--> 499\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgrad_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36m_assert_valid_dtypes\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[0mvalid_dtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_valid_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_dtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         raise ValueError(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C://Users//Greg//code//space physics//experiment//data\")\n",
    "\n",
    "mag_files = glob.glob(\"mag_data*.nc\")\n",
    "ss_file = ss_file = \"substorms_2000_2018.csv\"\n",
    "stats_file = \"statistics.npz\"\n",
    "data_interval = 120\n",
    "prediction_interval = 250\n",
    "\n",
    "gen = make_generator(mag_files, ss_file, stats_file, data_interval, prediction_interval)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(gen,\n",
    "                                         output_types = (tf.float32, tf.float32, tf.bool, tf.float32, tf.float32),\n",
    "                                         output_shapes = (tf.TensorShape([None, data_interval+1, 3]),\n",
    "                                                          tf.TensorShape([None, 3]),\n",
    "                                                          tf.TensorShape([]),\n",
    "                                                          tf.TensorShape([]),\n",
    "                                                          tf.TensorShape([3]))\n",
    "                                        )\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "data_iter = dataset.make_initializable_iterator()\n",
    "mag_input, st_loc, ss_occurred, ss_time, ss_loc = data_iter.get_next()\n",
    "global_params = None\n",
    "\n",
    "mag_features = station_conv(mag_input)\n",
    "st_features = station_net(mag_features, st_loc)\n",
    "global_features = global_conv(global_params)\n",
    "model_output = aggregator(st_features, global_features)\n",
    "\n",
    "loss = loss_function(model_output, ss_occurred, ss_time, ss_loc)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "STEPS = 10\n",
    "\n",
    "sess = tf.Session()\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(data_iter.initializer)\n",
    "    for _ in range(STEPS):\n",
    "        _, loss_val = sess.run([train_step, loss])\n",
    "        print(loss_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
